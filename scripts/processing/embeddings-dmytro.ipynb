{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f779b-afb2-4fb1-8bbf-12bdc83dc30a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install required packages\n",
    "required_packages = [\n",
    "    \"google-cloud-aiplatform\",\n",
    "    \"PyMuPDF\"\n",
    "]\n",
    "\n",
    "for package in required_packages:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Now import the libraries after installing\n",
    "import fitz  # PyMuPDF\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Set your Google Cloud project ID and index details\n",
    "PROJECT_ID = '625525962479'  # Update with your project ID\n",
    "INDEX_ID = 'gymbeam_advisor_1729933910721'  # Update with the correct index ID\n",
    "INDEX_ENDPOINT_ID = '2200078786714664960'\n",
    "LOCAL_PDF_DIR = 'in/files/'  # Local directory containing PDFs\n",
    "\n",
    "# Set the path to your service account key JSON file\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'datahackaton-projekt-2-5e5b5288a5fd.json'\n",
    "\n",
    "# Initialize Vertex AI\n",
    "aiplatform.init(project=PROJECT_ID, location='europe-north1')\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "# Function to create embeddings\n",
    "def create_embeddings(text):\n",
    "    prediction_client = aiplatform.gapic.PredictionServiceClient()\n",
    "\n",
    "    # Log the endpoint information\n",
    "    #endpoint = f'projects/{PROJECT_ID}/locations/europe-north1/endpoints/{INDEX_ENDPOINT_ID}'\n",
    "    endpoint = prediction_client.endpoint_path(project=PROJECT_ID, location=\"europe-north1\", endpoint=INDEX_ENDPOINT_ID)\n",
    "    \n",
    "    print(f\"Using endpoint: {endpoint}\")\n",
    "\n",
    "    # Create an instance for prediction\n",
    "    instances = [{'content': text}]\n",
    "\n",
    "    #try:\n",
    "    # Use the predict method to get the embedding\n",
    "    response = prediction_client.predict(\n",
    "        endpoint=endpoint,\n",
    "        instances=instances\n",
    "    )\n",
    "    #except Exception as e:\n",
    "     #   print(f\"An error occurred: {e}\")\n",
    "        #raise e\n",
    "      #  return None\n",
    "\n",
    "    # The response contains predictions\n",
    "    embeddings = response.predictions\n",
    "    return embeddings[0] if embeddings else None\n",
    "\n",
    "# Function to upload embeddings to the vector database\n",
    "def upload_embeddings_to_index(embeddings, metadata):\n",
    "    index_endpoint = aiplatform.gapic.IndexEndpointServiceClient()\n",
    "    index_endpoint.upsert(\n",
    "        index_endpoint=f'projects/{PROJECT_ID}/locations/europe-north1/indexEndpoints/{INDEX_ENDPOINT_ID}',\n",
    "        instances=[\n",
    "            {\n",
    "                'embedding': embedding,\n",
    "                'metadata': metadata\n",
    "            }\n",
    "            for embedding in embeddings\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    embeddings = []\n",
    "    metadata_list = []\n",
    "\n",
    "    # Process each PDF in the local directory\n",
    "    for filename in os.listdir(LOCAL_PDF_DIR):\n",
    "        if filename.endswith('.pdf'):\n",
    "            local_pdf_path = os.path.join(LOCAL_PDF_DIR, filename)\n",
    "\n",
    "            # Extract text from the PDF\n",
    "            text = extract_text_from_pdf(local_pdf_path)\n",
    "            print(f'Extracted text from {filename}')\n",
    "\n",
    "            # Create embeddings\n",
    "            embedding = create_embeddings(text)\n",
    "            embeddings.append(embedding)\n",
    "\n",
    "            # Store metadata (customize as needed)\n",
    "            metadata_list.append({'document_title': filename})\n",
    "\n",
    "            # Optionally, delete the local file after processing\n",
    "            # os.remove(local_pdf_path)  # Uncomment if you want to delete the PDF after processing\n",
    "\n",
    "    # Upload all embeddings to the vector index\n",
    "    upload_embeddings_to_index(embeddings, metadata_list)\n",
    "    print('All embeddings uploaded to the vector index.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ee474f-cc86-4611-8f3b-79ea0ad5fb17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
